{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5939e7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yfinance\n",
      "  Using cached yfinance-0.2.55-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /Users/himanshi/miniforge3/lib/python3.10/site-packages (from yfinance) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /Users/himanshi/miniforge3/lib/python3.10/site-packages (from yfinance) (2.2.5)\n",
      "Requirement already satisfied: requests>=2.31 in /Users/himanshi/miniforge3/lib/python3.10/site-packages (from yfinance) (2.31.0)\n",
      "Collecting multitasking>=0.0.7 (from yfinance)\n",
      "  Using cached multitasking-0.0.11-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /Users/himanshi/miniforge3/lib/python3.10/site-packages (from yfinance) (4.2.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in /Users/himanshi/miniforge3/lib/python3.10/site-packages (from yfinance) (2025.2)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /Users/himanshi/miniforge3/lib/python3.10/site-packages (from yfinance) (2.4.6)\n",
      "Collecting peewee>=3.16.2 (from yfinance)\n",
      "  Using cached peewee-3.17.9-cp310-cp310-macosx_11_0_arm64.whl\n",
      "Collecting beautifulsoup4>=4.11.1 (from yfinance)\n",
      "  Downloading beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4>=4.11.1->yfinance)\n",
      "  Downloading soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/himanshi/miniforge3/lib/python3.10/site-packages (from beautifulsoup4>=4.11.1->yfinance) (4.13.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/himanshi/miniforge3/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/himanshi/miniforge3/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/himanshi/miniforge3/lib/python3.10/site-packages (from requests>=2.31->yfinance) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/himanshi/miniforge3/lib/python3.10/site-packages (from requests>=2.31->yfinance) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/himanshi/miniforge3/lib/python3.10/site-packages (from requests>=2.31->yfinance) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/himanshi/miniforge3/lib/python3.10/site-packages (from requests>=2.31->yfinance) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.5 in /Users/himanshi/miniforge3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
      "Using cached yfinance-0.2.55-py2.py3-none-any.whl (109 kB)\n",
      "Downloading beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.3/187.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
      "Downloading soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: peewee, multitasking, soupsieve, beautifulsoup4, yfinance\n",
      "Successfully installed beautifulsoup4-4.13.4 multitasking-0.0.11 peewee-3.17.9 soupsieve-2.7 yfinance-0.2.55\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install yfinance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a88efa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for Crude Oil (CL=F)...\n",
      "✅ Saved to data/raw/CL_F.csv\n",
      "\n",
      "Fetching data for Gold (GC=F)...\n",
      "✅ Saved to data/raw/GC_F.csv\n",
      "\n",
      "Fetching data for S&P 500 E-mini (ES=F)...\n",
      "✅ Saved to data/raw/ES_F.csv\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Create folder for raw data\n",
    "os.makedirs(\"data/raw\", exist_ok=True)\n",
    "\n",
    "# Futures symbols\n",
    "futures = {\n",
    "    \"Crude Oil\": \"CL=F\",\n",
    "    \"Gold\": \"GC=F\",\n",
    "    \"S&P 500 E-mini\": \"ES=F\"\n",
    "}\n",
    "\n",
    "# Fetch and save data\n",
    "for name, symbol in futures.items():\n",
    "    print(f\"Fetching data for {name} ({symbol})...\")\n",
    "    data = yf.download(symbol, start=\"2015-01-01\", end=\"2025-04-22\", interval=\"1d\")\n",
    "    \n",
    "    # Fix: reset index to make date a column\n",
    "    data.reset_index(inplace=True)\n",
    "\n",
    "    # Save to CSV\n",
    "    file_path = f\"data/raw/{symbol.replace('=','_')}.csv\"\n",
    "    data.to_csv(file_path, index=False)\n",
    "    print(f\"✅ Saved to {file_path}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ec8acf",
   "metadata": {},
   "source": [
    "Data Cleaning & SQL Insertion\n",
    "🧹 Step 1: Clean & Standardize Data\n",
    "Let’s write a Python script to:\n",
    "\n",
    "Load each CSV\n",
    "\n",
    "Clean missing data\n",
    "\n",
    "Standardize column names\n",
    "\n",
    "Add symbol column\n",
    "\n",
    "Save a cleaned version and insert into a SQL table\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9d82eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sqlalchemy\n",
      "  Downloading sqlalchemy-2.0.40-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /Users/himanshi/miniforge3/lib/python3.10/site-packages (from sqlalchemy) (4.13.2)\n",
      "Downloading sqlalchemy-2.0.40-cp310-cp310-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sqlalchemy\n",
      "Successfully installed sqlalchemy-2.0.40\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sqlalchemy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0ed6fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Processing CL=F from data/raw/CL_F.csv...\n",
      "🔍 Original columns: ['Date', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
      "✅ Cleaned data saved to: data/processed/CL_F.csv\n",
      "📥 Inserted 2589 rows into 'futures_data' table.\n",
      "\n",
      "📦 Processing GC=F from data/raw/GC_F.csv...\n",
      "🔍 Original columns: ['Date', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
      "✅ Cleaned data saved to: data/processed/GC_F.csv\n",
      "📥 Inserted 2588 rows into 'futures_data' table.\n",
      "\n",
      "📦 Processing ES=F from data/raw/ES_F.csv...\n",
      "🔍 Original columns: ['Date', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
      "✅ Cleaned data saved to: data/processed/ES_F.csv\n",
      "📥 Inserted 2590 rows into 'futures_data' table.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "\n",
    "# Create output folders if they don't exist\n",
    "os.makedirs(\"data/processed\", exist_ok=True)\n",
    "os.makedirs(\"data/raw\", exist_ok=True)\n",
    "\n",
    "# Set up SQLite database\n",
    "engine = create_engine('sqlite:///data/futures_data.db')\n",
    "\n",
    "# Define futures files and symbols\n",
    "files = {\n",
    "    'CL=F': 'data/raw/CL_F.csv',\n",
    "    'GC=F': 'data/raw/GC_F.csv',\n",
    "    'ES=F': 'data/raw/ES_F.csv'\n",
    "}\n",
    "\n",
    "# Define expected numeric columns\n",
    "numeric_columns = ['open', 'high', 'low', 'close', 'volume']\n",
    "\n",
    "# Process each file\n",
    "for symbol, file_path in files.items():\n",
    "    print(f\"📦 Processing {symbol} from {file_path}...\")\n",
    "\n",
    "    try:\n",
    "        # Load the raw CSV\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Print original column names for inspection\n",
    "        print(f\"🔍 Original columns: {df.columns.tolist()}\")\n",
    "\n",
    "        # Normalize column names\n",
    "        df.columns = [col.strip().lower().replace(' ', '_') for col in df.columns]\n",
    "\n",
    "        # Check for 'date' column\n",
    "        if 'date' not in df.columns:\n",
    "            raise ValueError(f\"❌ 'date' column not found in: {file_path}\")\n",
    "\n",
    "        # Convert date column to datetime\n",
    "        df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "        # Convert numeric columns explicitly\n",
    "        for col in numeric_columns:\n",
    "            if col in df.columns:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "        # Drop rows with any missing or malformed data\n",
    "        df.dropna(subset=['date'] + numeric_columns, inplace=True)\n",
    "\n",
    "        # Add symbol column\n",
    "        df['symbol'] = symbol\n",
    "\n",
    "        # Reorder columns for consistency\n",
    "        ordered_cols = ['date'] + numeric_columns + ['symbol']\n",
    "        df = df[ordered_cols]\n",
    "\n",
    "        # Save cleaned data\n",
    "        cleaned_path = file_path.replace('raw', 'processed')\n",
    "        df.to_csv(cleaned_path, index=False)\n",
    "        print(f\"✅ Cleaned data saved to: {cleaned_path}\")\n",
    "\n",
    "        # Insert into SQL database\n",
    "        df.to_sql(\"futures_data\", con=engine, if_exists=\"append\", index=False)\n",
    "        print(f\"📥 Inserted {len(df)} rows into 'futures_data' table.\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❗ Error processing {symbol}: {e}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff40716",
   "metadata": {},
   "source": [
    "data is now:\n",
    "\n",
    "✅ Cleaned\n",
    "\n",
    "✅ Stored in SQLite (futures_data.db)\n",
    "\n",
    "✅ Structured for analysis with symbol, date, open, high, low, close, volume\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
